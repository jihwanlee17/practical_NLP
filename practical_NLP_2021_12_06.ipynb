{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58734cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# doc = \"I say hello you say goodbye. Say you love me and I will.\"\n",
    "# Style A\n",
    "def get_comatrix(doc, window_size=1):\n",
    "  lexicon, word_list = preprocessing(doc)\n",
    "  vocab_size = len(set(word_list))\n",
    "  matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "  for focus_idx, focus_word in enumerate(word_list):\n",
    "    left = max(0, (focus_idx - window_size))\n",
    "    right = min((focus_idx + window_size+1), len(word_list)) \n",
    "    for context_idx in range(left, right):\n",
    "      if focus_idx == context_idx:\n",
    "        pass\n",
    "      else:\n",
    "        if word_list[context_idx] in lexicon:\n",
    "          row = lexicon.index(focus_word) # row\n",
    "          col = lexicon.index(word_list[context_idx]) # col\n",
    "          matrix[row, col] += 1\n",
    "          \n",
    "  return matrix\n",
    "def preprocessing(doc):\n",
    "  word_list =  doc.replace('.', '').lower().split()\n",
    "  \n",
    "  bow = CountVectorizer(stop_words=None, token_pattern=r'\\b\\w+\\b') \n",
    "  bow.fit_transform([doc])\n",
    "  lexicon = bow.get_feature_names()\n",
    "  return lexicon, word_list\n",
    "df = pd.DataFrame(zero_matrix,\n",
    "             columns=lexicon,\n",
    "             index=lexicon)\n",
    "# Style B\n",
    "def get_indexes(doc):\n",
    "  word_list = doc.replace(\".\", \"\").lower().split()\n",
    "  word2idx = dict()\n",
    "  idx2word = dict()\n",
    "  for word in word_list:\n",
    "    if word not in word2idx:\n",
    "      index = len(word2idx)\n",
    "      word2idx[word] = index\n",
    "      idx2word[index] = word\n",
    "  doc_idx = [word2idx[word] for word in word_list]\n",
    "  return doc_idx, word2idx, idx2word\n",
    "def get_comatrix(doc_idx, window_size=1):\n",
    "  matrix = np.zeros((len(set(doc_idx)), len(set(doc_idx))), dtype=np.int32)\n",
    "  for focus_idx, focus_word_idx in enumerate(doc_idx):\n",
    "    for i in range(1, window_size+1):\n",
    "      left = focus_idx - window_size\n",
    "      right = focus_idx + window_size\n",
    "      if left >= 0:\n",
    "        left_idx = doc_idx[left]\n",
    "        matrix[focus_word_idx, left_idx] += 1\n",
    "      if right < doc_size:\n",
    "        right_idx = doc_idx[right]\n",
    "        matrix[focus_word_idx, right_idx] += 1\n",
    "  return matrix\n",
    "pd.DataFrame(zero_matrix,\n",
    "             columns=idx2word.values(),\n",
    "             index = idx2word.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
